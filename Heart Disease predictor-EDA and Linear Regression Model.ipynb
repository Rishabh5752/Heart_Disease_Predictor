{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7a6755",
   "metadata": {},
   "source": [
    "# Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3c1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b253f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope   \n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2  \\\n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "5   58    0   0       100   248    0        0      122      0      1.0      1   \n",
       "6   58    1   0       114   318    0        2      140      0      4.4      0   \n",
       "7   55    1   0       160   289    0        0      145      1      0.8      1   \n",
       "8   46    1   0       120   249    0        0      144      0      0.8      2   \n",
       "9   54    1   0       122   286    0        0      116      1      3.2      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  \n",
       "5   0     2       1  \n",
       "6   3     1       0  \n",
       "7   1     3       0  \n",
       "8   0     3       0  \n",
       "9   2     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv(\"heart_disease_data.csv\")\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb32e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e433e0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol   \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000  \\\n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak   \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000  \\\n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "254cf214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ff6829b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  trestbps  chol  fbs  restecg  thalach  exang  target\n",
       "0   52    1       125   212    0        1      168      0       0\n",
       "1   53    1       140   203    1        0      155      1       0\n",
       "2   70    1       145   174    0        1      125      1       0\n",
       "3   61    1       148   203    0        1      161      0       0\n",
       "4   62    0       138   294    1        1      106      0       0\n",
       "5   58    0       100   248    0        0      122      0       1\n",
       "6   58    1       114   318    0        2      140      0       0\n",
       "7   55    1       160   289    0        0      145      1       0\n",
       "8   46    1       120   249    0        0      144      0       0\n",
       "9   54    1       122   286    0        0      116      1       0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping extra columns:\n",
    "df2=df1.drop(['cp','thal','ca','slope','oldpeak'],axis='columns')\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "930a1c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if any null values are present in the dataset, and replacing them with the mean of the column\n",
    "df2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "541ac037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with the mean of the column\n",
    "df2.fillna(df2.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6171627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we'll have to replace the outliers in the dataser by replacing the outliers with the mean of that column\n",
    "#the threshold value is taken to be 3 as it's the standard value\n",
    "def handle_outliers(df, columns, threshold=3):\n",
    "    for col in columns:\n",
    "        if col != 'target':\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - (threshold * iqr)\n",
    "            upper_bound = q3 + (threshold * iqr)\n",
    "            df[col] = np.where(df[col] > upper_bound, upper_bound,\n",
    "                               np.where(df[col] < lower_bound, lower_bound, df[col]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d15ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the above function for the current dataset, df2\n",
    "df2 = handle_outliers(df2, df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fff8b",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e46a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X = df2.drop('target', axis=1)\n",
    "y = df2['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50abdef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# build linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca819069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -2.98190973e-01, -4.56087179e+02, -4.27418123e+07,\n",
       "       -7.45058060e-09,  8.85850834e-02,  0.00000000e+00, -3.72821304e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "748e41ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10323250975.478722"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0b3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.25897080535840233\n",
      "Mean Squared Error: 0.18431210836111167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# evaluate performance of model\n",
    "y_pred = lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "552582b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Residual plot')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize predicted vs actual values\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.title('Actual vs Predicted values')\n",
    "\n",
    "# Plot residuals\n",
    "plt.scatter(y_pred, y_test-y_pred)\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2721b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38 40]\n",
      " [12 78]]\n"
     ]
    }
   ],
   "source": [
    "# Set threshold value\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predicted values to binary classes\n",
    "y_pred_class = np.where(y_pred > threshold, 1, 0)\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34303e1",
   "metadata": {},
   "source": [
    "# Linear regression model using all variables\n",
    "As we can see by the r sqaured value, MSE, and the confusion matrix, that only taking the exisiting variables into account is not giving us an accurate model.\n",
    "So, we'll have to include all the variables that we first dropped from df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c1c477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying linear regression model on df1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80661f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# build linear regression model\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "591049c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.409608010607855\n",
      "Mean Squared Error: 0.1475944852005681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# evaluate performance of model\n",
    "y_pred = lr2.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c80312",
   "metadata": {},
   "source": [
    "# Data cleaning on df1\n",
    "As we can see, the r squared value increased from the previous value of 0.259, but still it is low. Hence, we'll now first clean the data and we'll have to remove the outliers present in the df2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa9248ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling handle_outliers function on df1\n",
    "df1 = handle_outliers(df1, df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3af4085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying linear regression model on df1 with outliers replaced by mean value of the column\n",
    "\n",
    "# split dataset into training and testing sets\n",
    "X = df1.drop('target', axis=1)\n",
    "y = df1['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dd9f4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# build linear regression model\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96e7c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.4111221310990536\n",
      "Mean Squared Error: 0.14721596408502893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# evaluate performance of model\n",
    "y_pred = lr2.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('R-squared:', r2)\n",
    "print('Mean Squared Error:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccaf8b8",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The r squared value even after replacing the outliers with the mean value remains around 0.411 which is low, hence by this observation it is safe to say that Linear regression model is not the best model for the above predicition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
